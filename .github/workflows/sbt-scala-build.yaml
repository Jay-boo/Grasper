name: Packaging
run-name: sbt-packaging / ${{github.actor}} on ${{github.event_name}}  
on:
  pull_request:
    branches: ['**']
  push:
    branches: ['**']


jobs:
  sbt-build-jar:
    name: Build and Test
    strategy:
      matrix:
        os: [ubuntu-latest]
        scala: [2.12.18]
        java: [temurin@8]
    runs-on: ${{ matrix.os }}
    steps:
      - name: Checkout current branch (full)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Java (temurin@8)
        if: matrix.java == 'temurin@8'
        uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: 8
          cache: sbt

      - name: Test project
        run: |
          cd InsightHoot
          sbt '++ ${{ matrix.scala }}' test

      - name: Build project jar
        run: |
          cd InsightHoot
          sbt '++ ${{ matrix.scala }}' assembly

      - name: Upload Jar Artifact
        uses: actions/upload-artifact@v4
        with:
          name: InsightHootJar
          path: ./jars/InsightHootKafka-3.5.1-8-2.12.jar


  create-cluster:
    runs-on: ubuntu-latest
    needs : [sbt-build-jar]
    steps:
      - name: Checkout current branch (full)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - uses: actions/download-artifact@v4
        with:
          name: InsightHootJar
          path: ./InsightHoot/jars

      - name: Create kind cluster
        uses: helm/kind-action@v1
        with:
          config: ./kind/k8s_config/kind-config.yaml

      - name: Setup Kafka
        run: |
          kubectl apply -f  kind/k8s_config/kafka
      - name: Helm install
        run: |
          helm repo add spark-operator https://kubeflow.github.io/spark-operator
          helm install my-release spark-operator/spark-operator --namespace spark-operator --create-namespace --set webhook.enable=true

      - name: Spark Operator
        run: |
          kubectl apply -f  kind/k8s_config/spark-pi.yaml

      - name: Sleep
        run: |
          sleep 30
          kubectl logs -n spark-operator spark-pi-driver
      - name: Check Spark application status
        run: |
          STATUS=$(kubectl get pods -n spark-operator spark-pi-driver --no-headers -o custom-columns=":status.phase")
          if [ "$STATUS" == "Running" ]; then
            echo "Pod is running"
          else
            echo "Pod is not running"
            exit 1
          fi



        

