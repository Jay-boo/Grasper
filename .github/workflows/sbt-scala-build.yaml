name: Packaging Scala project + k8s integration test
run-name: (sbt-packaging + k8s integration) / ${{github.actor}} on ${{github.event_name}}  
on:
  pull_request:
    branches: ['**']
  push:
    branches:
      - master
      - stable

jobs:
  deploy-django:
    uses: ./.github/workflows/django.yaml
    secrets: inherit
    permissions:
      packages: write
      contents: read
      attestations: write

  sbt-build-jar:
    name: Build and Test
    needs : [deploy-django]
    strategy:
      matrix:
        os: [ubuntu-latest]
        scala: [2.12.18]
        java: [temurin@8]
    runs-on: ${{ matrix.os }}
    steps:
      - name: Checkout current branch (full)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Java (temurin@8)
        if: matrix.java == 'temurin@8'
        uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: 8
          cache: sbt

      - name: Test project
        run: |
          cd InsightHoot
          sbt '++ ${{ matrix.scala }}' test

      - name: Build project jar
        run: |
          cd InsightHoot
          sbt '++ ${{ matrix.scala }}' assembly

      - name: Upload Jar Artifact
        uses: actions/upload-artifact@v4
        with:
          name: InsightHootJar
          path: ./jars/InsightHootKafka-3.5.1-8-2.12.jar




  create-cluster:
    runs-on: ubuntu-latest
    needs : [sbt-build-jar]
    steps:

      - name: Checkout current branch (full)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - uses: actions/download-artifact@v4
        with:
          name: InsightHootJar
          path: ./jars

      - name: Download Kafka source jar
        run: | 
          wget https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.5.1/spark-sql-kafka-0-10_2.12-3.5.1.jar
          mv spark-sql-kafka-0-10_2.12-3.5.1.jar ./jars
          wget https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_anc_en_3.0.0_3.0_1614962126490.zip
          unzip pos_anc_en_3.0.0_3.0_1614962126490.zip -d ./jars/pos_anc_en


      - name : See uploaded artifacts 
        run: ls ./jars


      - name: Create kind cluster
        uses: helm/kind-action@v1
        with:
          config: ./kind/k8s_config/kind-config.yaml

      - name: Setup Kafka
        run: |
          kubectl apply -f  kind/k8s_config/kafka
      - name: Helm install
        run: |
          helm repo add spark-operator https://kubeflow.github.io/spark-operator
          helm install my-release spark-operator/spark-operator --version 1.2.7 --namespace spark-operator --create-namespace --set webhook.enable=true --debug
          sleep 70


      - name: Spark Operator
        run: |
          kubectl apply -f  kind/k8s_config/spark-pi.yaml
          sleep 30

      # - name: Get logs kafka-connect
      #   run: |
      #     kubectl logs services/kafka-connect 
      #     
      #
      # - name: Get logs spark application driver
      #   run: |
      #     kubectl logs -n spark-operator spark-pi-driver

      - name: Check Spark Application status
        run: |
          while true; do
            APP_OUTPUT=$( kubectl get sparkapplications.sparkoperator.k8s.io -n spark-operator spark-pi)
            STATUS=$(echo "$APP_OUTPUT" | grep "spark-pi" | awk '{print $2}')
            echo $STATUS

            if [ "$STATUS" == "FAILED" ]; then
              echo "Spark Application Failed"
              exit 1
            elif [ "$STATUS" == "COMPLETED" ]; then
              echo "Spark Application Completed"
              exit 0
            else
              echo "Spark Application still running, Waiting ..."
              sleep 10
            fi
          done
