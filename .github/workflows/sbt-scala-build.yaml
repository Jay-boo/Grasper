name: Packaging
run-name: sbt-packaging / ${{github.actor}} on ${{github.event_name}}  
on:
  pull_request:
    branches: ['**']
  push:
    branches:
      - master
      - stable
      - cicd


jobs:
#   sbt-build-jar:
#     name: Build and Test
#     strategy:
#       matrix:
#         os: [ubuntu-latest]
#         scala: [2.12.18]
#         java: [temurin@8]
#     runs-on: ${{ matrix.os }}
#     steps:
#       - name: Checkout current branch (full)
#         uses: actions/checkout@v4
#         with:
#           fetch-depth: 0
#
#       - name: Setup Java (temurin@8)
#         if: matrix.java == 'temurin@8'
#         uses: actions/setup-java@v4
#         with:
#           distribution: temurin
#           java-version: 8
#           cache: sbt
#
#       - name: Test project
#         run: |
#           cd InsightHoot
#           sbt '++ ${{ matrix.scala }}' test
#
#       - name: Build project jar
#         run: |
#           cd InsightHoot
#           sbt '++ ${{ matrix.scala }}' assembly
#
#       - name: Upload Jar Artifact
#         uses: actions/upload-artifact@v4
#         with:
#           name: InsightHootJar
#           path: ./jars/InsightHootKafka-3.5.1-8-2.12.jar


  create-cluster:
    runs-on: ubuntu-latest
    steps:

      - name: Checkout current branch (full)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # - uses: actions/download-artifact@v4
      #   with:
      #     name: InsightHootJar
      #     path: ./jars




      - name: Create kind cluster
        uses: helm/kind-action@v1
        with:
          config: ./kind/k8s_config/kind-config.yaml

      # - name: Setup Kafka
      #   run: |
      #     kubectl apply -f  kind/k8s_config/kafka

      - name: Helm install bitnami
        run: |
          kubectl version
      - name: Helm install
        run: |
          helm repo add spark-operator https://kubeflow.github.io/spark-operator
          helm search repo spark-operator
          helm repo update
          helm install my-release spark-operator/spark-operator --namespace spark-operator --create-namespace --set image.tag=v1beta2-1.2.3-3.1.1--set webhook.enable=true --debug




      # - name: Get logs kafka-connect
      #   run: |
      #     kubectl logs services/kafka-connect 
      #     
      #
      # - name: Get logs spark application driver
      #   run: |
      #     kubectl logs -n spark-operator spark-pi-driver

